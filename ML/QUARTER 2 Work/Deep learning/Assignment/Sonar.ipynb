{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "0  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "1  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "2  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "3  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "4  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "\n",
       "   0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  \\\n",
       "0  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "1  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "2  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "3  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "4  0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
       "\n",
       "   0.0090  0.0032  R  \n",
       "0  0.0052  0.0044  R  \n",
       "1  0.0095  0.0078  R  \n",
       "2  0.0040  0.0117  R  \n",
       "3  0.0107  0.0094  R  \n",
       "4  0.0051  0.0062  R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar = pd.read_csv(\"datasets/sonar.csv\")\n",
    "sonar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.1627</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>0.2696</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.3513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.1168</td>\n",
       "      <td>0.1476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.1543</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "80   0.0100  0.0194  0.0155  0.0489  0.0839  0.1009  0.1627  0.2071  0.2696   \n",
       "5    0.0317  0.0956  0.1321  0.1408  0.1674  0.1710  0.0731  0.1401  0.2083   \n",
       "167  0.0015  0.0186  0.0289  0.0195  0.0515  0.0817  0.1005  0.0124  0.1168   \n",
       "58   0.0125  0.0152  0.0218  0.0175  0.0362  0.0696  0.0873  0.0616  0.1252   \n",
       "106  0.0428  0.0555  0.0708  0.0618  0.1215  0.1524  0.1543  0.0391  0.0610   \n",
       "\n",
       "     0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  \\\n",
       "80   0.2990  ...  0.0130  0.0073  0.0077  0.0075  0.0060  0.0080  0.0019   \n",
       "5    0.3513  ...  0.0201  0.0248  0.0131  0.0070  0.0138  0.0092  0.0143   \n",
       "167  0.1476  ...  0.0108  0.0075  0.0089  0.0036  0.0029  0.0013  0.0010   \n",
       "58   0.1302  ...  0.0041  0.0074  0.0030  0.0050  0.0048  0.0017  0.0041   \n",
       "106  0.0113  ...  0.0142  0.0179  0.0079  0.0060  0.0131  0.0089  0.0084   \n",
       "\n",
       "     0.0090  0.0032  R  \n",
       "80   0.0053  0.0019  R  \n",
       "5    0.0036  0.0103  R  \n",
       "167  0.0032  0.0047  M  \n",
       "58   0.0086  0.0058  R  \n",
       "106  0.0113  0.0049  M  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar = sonar.sample(frac = 1)\n",
    "sonar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.83579208, -0.57776433, -0.73740932, ..., -0.9346337 ,\n",
       "        -0.4265097 , -0.91989765],\n",
       "       [ 0.10842322,  1.73414308,  2.29683303, ...,  0.98197394,\n",
       "        -0.70154866,  0.75149005],\n",
       "       [-1.20564599, -0.60203632, -0.38870565, ..., -1.07374232,\n",
       "        -0.76626371, -0.36276841],\n",
       "       ...,\n",
       "       [-0.42242593, -0.52011834, -0.98982913, ...,  0.2400613 ,\n",
       "        -0.9442301 , -0.24338358],\n",
       "       [ 1.46600465,  2.064849  ,  2.83029759, ..., -0.3472862 ,\n",
       "         0.54421605,  1.30861929],\n",
       "       [-0.68785051, -0.64451231, -0.6775572 , ..., -0.85735113,\n",
       "        -0.84715752, -0.48215325]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_new = sonar.drop([\"R\"], axis = 1).values\n",
    "scale = StandardScaler()\n",
    "sonar_new_scale = scale.fit_transform(sonar_new)\n",
    "sonar_new_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 60)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80     R\n",
      "5      R\n",
      "167    M\n",
      "58     R\n",
      "106    M\n",
      "      ..\n",
      "59     R\n",
      "56     R\n",
      "31     R\n",
      "99     M\n",
      "169    M\n",
      "Name: R, Length: 207, dtype: object\n"
     ]
    }
   ],
   "source": [
    "target = sonar[\"R\"]\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0\n",
      " 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 0 1 1 1 1 0 0\n",
      " 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0\n",
      " 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0\n",
      " 1 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "target_enc = le.fit_transform(target)\n",
    "print(target_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "target_ohe = tf.keras.utils.to_categorical(target_enc)\n",
    "print(target_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sonar_new_scale, target_ohe, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 60)\n",
      "(165, 2)\n",
      "(42, 60)\n",
      "(42, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(0.2, input_shape = (60,)))\n",
    "model.add(Dense(60, activation = \"relu\"))\n",
    "model.add(Dense(30, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize = Adam(learning_rate = 0.005)\n",
    "\n",
    "model.compile(optimizer = optimize,\n",
    "             loss = \"categorical_crossentropy\",\n",
    "             metrics = [\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 17 samples\n",
      "Epoch 1/40\n",
      "148/148 [==============================] - 1s 4ms/sample - loss: 0.6806 - acc: 0.6757 - val_loss: 0.5926 - val_acc: 0.5882\n",
      "Epoch 2/40\n",
      "148/148 [==============================] - 0s 423us/sample - loss: 0.4230 - acc: 0.8176 - val_loss: 0.5857 - val_acc: 0.5882\n",
      "Epoch 3/40\n",
      "148/148 [==============================] - 0s 391us/sample - loss: 0.4377 - acc: 0.8378 - val_loss: 0.6255 - val_acc: 0.6471\n",
      "Epoch 4/40\n",
      "148/148 [==============================] - 0s 398us/sample - loss: 0.4219 - acc: 0.7838 - val_loss: 0.4391 - val_acc: 0.7647\n",
      "Epoch 5/40\n",
      "148/148 [==============================] - 0s 371us/sample - loss: 0.3494 - acc: 0.8784 - val_loss: 0.4109 - val_acc: 0.7059\n",
      "Epoch 6/40\n",
      "148/148 [==============================] - 0s 398us/sample - loss: 0.3062 - acc: 0.8446 - val_loss: 0.4276 - val_acc: 0.7647\n",
      "Epoch 7/40\n",
      "148/148 [==============================] - 0s 411us/sample - loss: 0.2933 - acc: 0.9054 - val_loss: 0.3786 - val_acc: 0.7059\n",
      "Epoch 8/40\n",
      "148/148 [==============================] - 0s 364us/sample - loss: 0.3417 - acc: 0.8649 - val_loss: 0.3939 - val_acc: 0.7647\n",
      "Epoch 9/40\n",
      "148/148 [==============================] - 0s 364us/sample - loss: 0.3016 - acc: 0.8514 - val_loss: 0.4706 - val_acc: 0.7059\n",
      "Epoch 10/40\n",
      "148/148 [==============================] - 0s 377us/sample - loss: 0.2617 - acc: 0.8986 - val_loss: 0.3137 - val_acc: 0.7647\n",
      "Epoch 11/40\n",
      "148/148 [==============================] - 0s 377us/sample - loss: 0.2072 - acc: 0.9189 - val_loss: 0.2389 - val_acc: 0.8824\n",
      "Epoch 12/40\n",
      "148/148 [==============================] - 0s 377us/sample - loss: 0.2013 - acc: 0.9257 - val_loss: 0.2950 - val_acc: 0.8235\n",
      "Epoch 13/40\n",
      "148/148 [==============================] - 0s 357us/sample - loss: 0.1989 - acc: 0.9122 - val_loss: 0.4184 - val_acc: 0.8824\n",
      "Epoch 14/40\n",
      "148/148 [==============================] - 0s 377us/sample - loss: 0.2031 - acc: 0.9324 - val_loss: 0.6286 - val_acc: 0.7647\n",
      "Epoch 15/40\n",
      "148/148 [==============================] - 0s 364us/sample - loss: 0.1820 - acc: 0.9392 - val_loss: 0.3295 - val_acc: 0.9412\n",
      "Epoch 16/40\n",
      "148/148 [==============================] - 0s 357us/sample - loss: 0.2178 - acc: 0.9122 - val_loss: 0.4248 - val_acc: 0.8235\n",
      "Epoch 17/40\n",
      "148/148 [==============================] - 0s 350us/sample - loss: 0.2223 - acc: 0.9054 - val_loss: 0.4057 - val_acc: 0.7647\n",
      "Epoch 18/40\n",
      "148/148 [==============================] - 0s 418us/sample - loss: 0.2510 - acc: 0.9054 - val_loss: 0.3270 - val_acc: 0.9412\n",
      "Epoch 19/40\n",
      "148/148 [==============================] - 0s 627us/sample - loss: 0.1277 - acc: 0.9662 - val_loss: 0.2035 - val_acc: 0.9412\n",
      "Epoch 20/40\n",
      "148/148 [==============================] - 0s 492us/sample - loss: 0.1605 - acc: 0.9392 - val_loss: 0.2884 - val_acc: 0.9412\n",
      "Epoch 21/40\n",
      "148/148 [==============================] - 0s 526us/sample - loss: 0.0775 - acc: 0.9797 - val_loss: 0.3154 - val_acc: 0.9412\n",
      "Epoch 22/40\n",
      "148/148 [==============================] - 0s 526us/sample - loss: 0.2142 - acc: 0.9257 - val_loss: 0.3090 - val_acc: 0.8235\n",
      "Epoch 23/40\n",
      "148/148 [==============================] - 0s 532us/sample - loss: 0.1372 - acc: 0.9392 - val_loss: 0.3025 - val_acc: 0.8824\n",
      "Epoch 24/40\n",
      "148/148 [==============================] - 0s 506us/sample - loss: 0.1649 - acc: 0.9257 - val_loss: 0.2375 - val_acc: 0.8235\n",
      "Epoch 25/40\n",
      "148/148 [==============================] - 0s 553us/sample - loss: 0.1188 - acc: 0.9527 - val_loss: 0.4079 - val_acc: 0.7647\n",
      "Epoch 26/40\n",
      "148/148 [==============================] - 0s 519us/sample - loss: 0.1483 - acc: 0.9459 - val_loss: 0.3352 - val_acc: 0.9412\n",
      "Epoch 27/40\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.2503 - acc: 0.913 - 0s 519us/sample - loss: 0.2938 - acc: 0.8986 - val_loss: 0.2727 - val_acc: 0.8824\n",
      "Epoch 28/40\n",
      "148/148 [==============================] - 0s 519us/sample - loss: 0.1417 - acc: 0.9459 - val_loss: 0.1536 - val_acc: 0.9412\n",
      "Epoch 29/40\n",
      "148/148 [==============================] - 0s 492us/sample - loss: 0.2351 - acc: 0.8919 - val_loss: 0.3057 - val_acc: 0.8824\n",
      "Epoch 30/40\n",
      "148/148 [==============================] - 0s 411us/sample - loss: 0.2153 - acc: 0.9122 - val_loss: 0.2894 - val_acc: 0.8824\n",
      "Epoch 31/40\n",
      "148/148 [==============================] - 0s 350us/sample - loss: 0.2069 - acc: 0.9189 - val_loss: 0.3653 - val_acc: 0.7647\n",
      "Epoch 32/40\n",
      "148/148 [==============================] - 0s 391us/sample - loss: 0.1953 - acc: 0.9324 - val_loss: 0.2752 - val_acc: 0.9412\n",
      "Epoch 33/40\n",
      "148/148 [==============================] - 0s 377us/sample - loss: 0.2635 - acc: 0.8919 - val_loss: 0.3009 - val_acc: 0.8824\n",
      "Epoch 34/40\n",
      "148/148 [==============================] - 0s 384us/sample - loss: 0.1617 - acc: 0.9392 - val_loss: 0.3507 - val_acc: 0.8235\n",
      "Epoch 35/40\n",
      "148/148 [==============================] - 0s 377us/sample - loss: 0.1890 - acc: 0.9595 - val_loss: 0.3734 - val_acc: 0.9412\n",
      "Epoch 36/40\n",
      "148/148 [==============================] - 0s 391us/sample - loss: 0.1496 - acc: 0.9324 - val_loss: 0.2652 - val_acc: 0.8824\n",
      "Epoch 37/40\n",
      "148/148 [==============================] - 0s 404us/sample - loss: 0.1520 - acc: 0.9459 - val_loss: 0.3391 - val_acc: 0.8824\n",
      "Epoch 38/40\n",
      "148/148 [==============================] - 0s 532us/sample - loss: 0.1531 - acc: 0.9189 - val_loss: 0.1949 - val_acc: 0.8824\n",
      "Epoch 39/40\n",
      "148/148 [==============================] - 0s 512us/sample - loss: 0.1500 - acc: 0.9392 - val_loss: 0.2292 - val_acc: 0.8824\n",
      "Epoch 40/40\n",
      "148/148 [==============================] - 0s 505us/sample - loss: 0.1050 - acc: 0.9595 - val_loss: 0.2611 - val_acc: 0.8824\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size = 6, epochs = 40, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 - 0s - loss: 0.2418 - acc: 0.9286\n",
      "['loss', 'acc']\n",
      "[0.24175661784552394, 0.9285714]\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(x_test, y_test, verbose = 2)\n",
    "print(model.metrics_names)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes(x_test)[0]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
